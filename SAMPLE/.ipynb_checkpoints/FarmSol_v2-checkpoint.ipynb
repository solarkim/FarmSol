{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n입출력 양식을 \\n준수해 주십시오\\n\\n###  INPUT ###\\nimport pandas as pd\\ninput_data = pd.read_csv(\\'2023_smartFarm_AI_hackathon_dataset.csv\\')\\n\\n{\\n    \\n        Write codes...\\n    \\n    Training model name : model\\n    ex) y_pred = model.predict(X_test)\\n    \\n\\n}\\n\\n\\n### OUTPUT ###\\nprint(\"RMSE:\", rmse)\\nprint(\"R2_score:\", r2score)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  -------------------------------------------\n",
    "\"\"\"\n",
    "입출력 양식을 \n",
    "준수해 주십시오\n",
    "\n",
    "###  INPUT ###\n",
    "import pandas as pd\n",
    "input_data = pd.read_csv('2023_smartFarm_AI_hackathon_dataset.csv')\n",
    "\n",
    "{\n",
    "    \n",
    "        Write codes...\n",
    "    \n",
    "    Training model name : model\n",
    "    ex) y_pred = model.predict(X_test)\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "### OUTPUT ###\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2_score:\", r2score)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "\n",
    "import numpy.random as nr\n",
    "import scipy.stats as ss\n",
    "import math\n",
    "\n",
    "import time\n",
    "from keras.callbacks import EarlyStopping  \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn import linear_model\n",
    "\n",
    "# def print_metrics(y_true, y_predicted, n_parameters):\n",
    "#     ## First compute R^2 and the adjusted R^2\n",
    "#     r2 = sklm.r2_score(y_true, y_predicted)\n",
    "#     r2_adj = r2 - (n_parameters - 1)/(y_true.shape[0] - n_parameters) * (1 - r2)\n",
    "\n",
    "\n",
    "#     ## Print the usual metrics and the R^2 values\n",
    "#     # print('Mean Square Error      = ' + str(sklm.mean_squared_error(y_true, y_predicted)))\n",
    "#     print('Root Mean Square Error = ' + str(math.sqrt(sklm.mean_squared_error(y_true, y_predicted))))\n",
    "#     # print('Mean Absolute Error    = ' + str(sklm.mean_absolute_error(y_true, y_predicted)))\n",
    "#     # print('Median Absolute Error  = ' + str(sklm.median_absolute_error(y_true, y_predicted)))\n",
    "#     print('R^2                    = ' + str(r2*100))\n",
    "#     # print('Adjusted R^2           = ' + str(r2_adj))\n",
    "\n",
    "#     return sklm.mean_squared_error(y_true, y_predicted), r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_input2(df):\n",
    "    Features = df\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "\n",
    "    n_future = 1  # Number of days we want to predict into the future\n",
    "    n_past = 16  # Number of past days we want to use to predict the future\n",
    "\n",
    "    labels = np.array([row[0] for row in Features])\n",
    "\n",
    "    indx = range(Features.shape[0])\n",
    "    indx = ms.train_test_split(indx, test_size=0.2, shuffle=False)\n",
    "    \n",
    "    # Features_train_x = sc.fit_transform(Features[0:len(indx[0]) + 1, 1:16])\n",
    "    # Features_train_y = sc.fit_transform(Features[0:len(indx[0]) + 1, 0:2])\n",
    "\n",
    "    Features_train_x = sc.fit_transform(Features[0:len(indx[0]) + 1, 1:16])\n",
    "    Features_train_y = sc.fit_transform(Features[0:len(indx[0]) + 1, 0:2])  # 2개의 y 변수를 포함하도록 수정\n",
    "\n",
    "    Features_train = np.hstack([Features_train_y, Features_train_x])\n",
    "\n",
    "    Features_test_x = sc.fit_transform(Features[len(indx[0]) - n_past:len(Features), 1:16])\n",
    "    Features_test_y = sc.fit_transform(Features[len(indx[0]) - n_past:len(Features), 0:2])  # 2개의 y 변수를 포함하도록 수정\n",
    "\n",
    "    Features_test = np.hstack([Features_test_y, Features_test_x])\n",
    "\n",
    "    for i in range(n_past, len(indx[0]) - n_future + 1):\n",
    "        x_train.append(Features_train[i - n_past:i, :])  # 모든 feature를 포함하도록 수정\n",
    "        y_train.append(Features_train[i:i + n_future, 0:2])  # 2개의 y 변수를 포함하도록 수정\n",
    "\n",
    "    for i in range(n_past, n_past + len(indx[1])):\n",
    "        x_test.append(Features_test[i - n_past:i, :])  # 모든 feature를 포함하도록 수정\n",
    "        y_test.append(Features_test[i:i + n_future, 0:2])  # 2개의 y 변수를 포함하도록 수정\n",
    "\n",
    "    x_train, y_train, x_test, y_test = np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def LSTM_input(df):\n",
    "    \n",
    "#     Features=df\n",
    "#     x_train = []\n",
    "#     y_train = []\n",
    "#     x_test = []\n",
    "#     y_test = []\n",
    "\n",
    "#     n_future = 1  # Number of days we want top predict into the future\n",
    "#     n_past = 16 # Number of past days we want to use to predict the future\n",
    "\n",
    "#     labels = np.array([row[0] for row in Features])\n",
    "#     # print(labels.shape)\n",
    "    \n",
    "#     indx = range(Features.shape[0])\n",
    "#     indx = ms.train_test_split(indx, test_size = 0.2, shuffle=False)\n",
    "\n",
    "#     #Features_train = sc.fit_transform(Features[0:len(indx[0])+1,:])\n",
    "#     #Features_test = sc.fit_transform(Features[len(indx[0])-n_past:len(Features),:])\n",
    "#     Features_train_x = sc.fit_transform(Features[0:len(indx[0])+1,1:16])\n",
    "#     Features_train_y = sc.fit_transform(Features[0:len(indx[0])+1,0:1])\n",
    "#     print(Features_train_y)\n",
    "#     Features_train = np.hstack([Features_train_y,Features_train_x])\n",
    "\n",
    "#     Features_test_x = sc.fit_transform(Features[len(indx[0])-n_past:len(Features),1:16])\n",
    "#     Features_test_y = sc.fit_transform(Features[len(indx[0])-n_past:len(Features),0:1])\n",
    "\n",
    "#     Features_test = np.hstack([Features_test_y,Features_test_x])\n",
    "\n",
    "#     for i in range(n_past, len(indx[0]) - n_future +1):\n",
    "#         x_train.append(Features_train[i - n_past:i, 0:Features.shape[1]])\n",
    "#         y_train.append(Features_train[i:i + n_future ,0])\n",
    "\n",
    "#     for i in range(n_past, n_past+len(indx[1])):\n",
    "#         x_test.append(Features_test[i - n_past :i, 0:Features.shape[1]])\n",
    "#         y_test.append(Features_test[i:i + n_future,0])\n",
    "\n",
    "#     x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "#     x_test, y_test = np.array(x_test), np.array(y_test)\n",
    "#     # comment out this box and uncomment load_model to load saved model\n",
    "#     ###################################################################################\n",
    "\n",
    "#     return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepro(df):\n",
    "    input_data = df\n",
    "    # input_data=input_data.groupby(\"frmDist\")\n",
    "    # flist = input_data[\"frmDist\"].unique()\n",
    "\n",
    "    # for p in flist[:1]:\n",
    "    #     input_data.get_group(p)\n",
    "    input_data.loc[input_data[\"outtrn_cumsum\"]==0,\"outtrn_cumsum\"]=None\n",
    "    input_data[\"outtrn_cumsum\"]=input_data[\"outtrn_cumsum\"].fillna(method='ffill' or 'pad')\n",
    "    # input_data=input_data.dropna(subset=['outtrn_cumsum'])\n",
    "    input_data.loc[input_data[\"HeatingEnergyUsage_cumsum\"]==0,\"HeatingEnergyUsage_cumsum\"]=None\n",
    "    input_data[\"HeatingEnergyUsage_cumsum\"]=input_data[\"HeatingEnergyUsage_cumsum\"].fillna(method='ffill' or 'pad')\n",
    "    \n",
    "    # 0 값을 NaN으로 바꾸기\n",
    "    input_data = input_data.replace(0, np.nan)\n",
    "    # frtstCo(열매 수) 누적값으로 바꾸기\n",
    "    input_data['frtstCo'] = input_data['frtstCo'].cumsum()\n",
    "    input_data['outTp_minus_inTp'] = input_data['outTp_minus_inTp'].cumsum()\n",
    "    # input_data=input_data.dropna(subset=['HeatingEnergyUsage_cumsum'])\n",
    "    input_data = input_data.interpolate()\n",
    "    input_data = input_data.replace(np.nan,0)\n",
    "    \n",
    "    return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2121/2121 [==============================] - 36s 16ms/step - loss: 0.0160 - val_loss: 0.0123\n",
      "531/531 [==============================] - 4s 6ms/step\n",
      "RMSE: 606.9357581176149\n",
      "R2_score: 0.7702037943815494\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# ------------------------------------------------\n",
    "\n",
    "\n",
    "#      SAMPLE MODEL\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "\n",
    "\n",
    "###  INPUT ###\n",
    "\"\"\"\n",
    "\n",
    "Read CSV files from the given list of file paths and return DataFrames.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "input_data = pd.read_csv(\"2023_smartFarm_AI_hackathon_dataset.csv\")\n",
    "#  -------------------------------------------\n",
    "###    Write codes...  ###\n",
    "#      EXAMPLE CODE      #\n",
    "df_delna = input_data.drop(['daysuplyqy', 'lefstalklt', 'frtstSetCo', 'pllnLt', 'flanJnt', 'hvstJnt', 'flwrCo', 'frtstJnt'], axis=1)\n",
    "df_delna.sort_values(by=[\"frmDist\",\"date\"],ascending=True,inplace=True)\n",
    "jflist=df_delna[\"frmDist\"].unique()\n",
    "fj_env=df_delna.groupby(\"frmDist\")\n",
    "\n",
    "# Read CSV files from the lists of file paths\n",
    "\n",
    "\n",
    "# Now you have lists of DataFrames for each type of data \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ... (Data preprocessing code here)\n",
    "\n",
    "flist = input_data[\"frmDist\"].unique()\n",
    "input_data=input_data.drop(['daysuplyqy', 'lefstalklt', 'frtstSetCo', 'pllnLt', 'flanJnt', 'hvstJnt', 'flwrCo', 'frtstJnt'],axis=1)\n",
    "input_data.sort_values(by=[\"frmDist\",\"date\"],ascending=True,inplace=True)\n",
    "\n",
    "input_data = input_data.copy()\n",
    "\n",
    "input_data['inTp'].replace(0, np.nan, inplace=True)\n",
    "input_data['outTp'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "input_data['mmdd'] = input_data['date'].astype(str).str[4:]\n",
    "\n",
    "# 'mmdd'를 기준으로 그룹화하여 변수값의 평균을 계산하고 대체\n",
    "input_data['inTp'].fillna(input_data.groupby('mmdd')['inTp'].transform('mean'), inplace=True)\n",
    "input_data['outTp'].fillna(input_data.groupby('mmdd')['outTp'].transform('mean'), inplace=True)\n",
    "\n",
    "# input_data_r.drop(['mmdd'], axis=1, inplace=True)\n",
    "input_data['inTp'].fillna(0, inplace=True)\n",
    "input_data['outTp'].fillna(0, inplace=True)\n",
    "\n",
    "# 뺀 변수 만들기\n",
    "input_data['outTp_minus_inTp'] = input_data['inTp'] - input_data['outTp']\n",
    "\n",
    "empty_df = pd.DataFrame()\n",
    "for p in flist:\n",
    "    df=fj_env.get_group(p)\n",
    "    df=df.reindex(columns=[\"date\",\"outtrn_cumsum\",'HeatingEnergyUsage_cumsum',\"inTp\",\"outTp\",\"inHd\",\"inCo2\",\"outWs\",\"acSlrdQy\",\"ec\",\"ph\",\n",
    "                        \"frtstGrupp\",\"flanGrupp\",\"frtstCo\", 'tcdmt', 'frmhsFclu', 'hvstGrupp',\n",
    "                        'grwtLt', 'fcluHg', 'lefLt', 'hvstCo', 'lefCunt',\n",
    "                        'lefBt', 'stemThck', 'frmAr', 'frmDov','outTp_minus_inTp'\n",
    "                        ])\n",
    "    df=prepro(df)\n",
    "    df=df.set_index(\"date\")\n",
    "    empty_df=pd.concat([empty_df, df], axis = 0)\n",
    "    # Initialize and train the LinearRegression model\n",
    "empty_df=empty_df.reset_index()\n",
    "dataset_train_actual = empty_df.copy()\n",
    "dataset_train_actual['date']= dataset_train_actual['date'].astype('str')\n",
    "dataset_train_actual['date']=pd.to_datetime(dataset_train_actual['date'])\n",
    "dataset_train_timeindex = dataset_train_actual.set_index('date')\n",
    "\n",
    "# cols = list(dataset_train)[1:24]\n",
    "\n",
    "# datelist_train 그림그리기위한 시간 열\n",
    "# datelist_train = list(dataset_train['date'])\n",
    "# datelist_train = [date for date in datelist_train]\n",
    "\n",
    "# #     print('Training set shape == {}'.format(dataset_train.shape))\n",
    "# #     print('All timestamps == {}'.format(len(datelist_train)))\n",
    "# #     print('Featured selected: {}'.format(cols))\n",
    "# # dataset_train -> copy본\n",
    "#---------------------------------------------------------------------\n",
    "### 변수 나누는 부분\n",
    "dataset_train = dataset_train_actual.copy()\n",
    "\n",
    "# # training and predictions 포함된 열 선택\n",
    "cols = list(dataset_train)[1:25]\n",
    "# print(cols)\n",
    "# # # datelist_train 그림그리기위한 시간 열\n",
    "datelist_train = list(dataset_train['date'])\n",
    "datelist_train = [date for date in datelist_train]\n",
    "dataset_train = dataset_train[cols].astype(str)\n",
    "# # # for i in cols:\n",
    "# #     for j in range(0, len(dataset_train)):\n",
    "# #         dataset_train[i][j] = dataset_train[i][j].replace(',', '')\n",
    "\n",
    "# # datelist_train float 타입으로 바꿔주기\n",
    "dataset_train = dataset_train.astype(float)\n",
    "\n",
    "# # 여러 feature값 (predictors)\n",
    "training_set = dataset_train.values\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sc = MinMaxScaler()\n",
    "# train_set_scale = sc.fit_transform(training_set[:,1:])\n",
    "#---------------------------------------------------------------------\n",
    "\n",
    "# train_set_scale=np.append(training_set[:, 0:1],train_set_scale,axis=1)\n",
    "# train_set_scale\n",
    "\n",
    "# x_train, y_train, x_test, y_test = LSTM_input2(train_set_scale)\n",
    "\n",
    "x_train, y_train, x_test, y_test = LSTM_input2(training_set)\n",
    "\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(int(32), input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(Dropout(.3))\n",
    "model.add(Dense(2, activation='relu'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train,y_train,\n",
    "          epochs=1,\n",
    "          batch_size=32,\n",
    "          validation_data=(x_test, y_test),\n",
    "          verbose=1,\n",
    "          shuffle=False,\n",
    "          # callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)]\n",
    "         )\n",
    "y_pred = sc.inverse_transform(model.predict(x_test))\n",
    "# print(y_pred.shape)\n",
    "# print(y_test.shape)\n",
    "# Calculate RMSE between the predictions and actual 'y' values\n",
    "\n",
    "def calculate_rmse(targets, predictions):\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Squared Error (RMSE) between predicted and target values.\n",
    "\n",
    "    :param predictions: Predicted values.\n",
    "    :type predictions: array-like\n",
    "    :param targets: Target values.\n",
    "    :type targets: array-like\n",
    "    :return: RMSE value.\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    return np.sqrt(mean_squared_error(targets, sc.inverse_transform(predictions)))\n",
    "\n",
    "\n",
    "# Calculate r2_score between the predictions and actual 'y' values\n",
    "def calculate_R2_score(y_test,y_score):\n",
    "    # n_parameters=x_train.shape[1]\n",
    "    # y_score = sc.inverse_transform(model.predict(x_test))\n",
    "    # print(y_score.shape)\n",
    "    # rmse, r2score = print_metrics(sc.inverse_transform(y_test), y_score, n_parameters)\n",
    "    # print(\"RMSE:\", rmse)\n",
    "    # print(\"R2_score:\", r2score)\n",
    "    from sklearn.metrics import r2_score\n",
    "    r2 = sklm.r2_score(y_test, y_score)\n",
    "    return r2\n",
    "\n",
    "y_train=y_train.reshape(-1,2)\n",
    "y_test=y_test.reshape(-1,2)\n",
    "y_test=pd.DataFrame(sc.inverse_transform(y_test),columns = ['outtrn_cumsum','HeatingEnergyUsage_cumsum'])\n",
    "rmse = calculate_rmse(y_test, y_pred)\n",
    "r2score = calculate_R2_score(y_test, y_pred)\n",
    "# Predict 'y' values using the trained model\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# ------------------------------------------------\n",
    "### OUTPUT ###\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"R2_score:\", r2score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outtrn_cumsum</th>\n",
       "      <th>HeatingEnergyUsage_cumsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.492646</td>\n",
       "      <td>21.484669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.323035</td>\n",
       "      <td>15.276258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.576610</td>\n",
       "      <td>18.416166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.266500</td>\n",
       "      <td>20.065615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.124594</td>\n",
       "      <td>19.119871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16963</th>\n",
       "      <td>23.096991</td>\n",
       "      <td>27.725501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16964</th>\n",
       "      <td>23.096991</td>\n",
       "      <td>27.725501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16965</th>\n",
       "      <td>23.096991</td>\n",
       "      <td>27.725501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16966</th>\n",
       "      <td>23.096991</td>\n",
       "      <td>27.725501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16967</th>\n",
       "      <td>23.096991</td>\n",
       "      <td>27.725501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16968 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       outtrn_cumsum  HeatingEnergyUsage_cumsum\n",
       "0          22.492646                  21.484669\n",
       "1          25.323035                  15.276258\n",
       "2          21.576610                  18.416166\n",
       "3          21.266500                  20.065615\n",
       "4          20.124594                  19.119871\n",
       "...              ...                        ...\n",
       "16963      23.096991                  27.725501\n",
       "16964      23.096991                  27.725501\n",
       "16965      23.096991                  27.725501\n",
       "16966      23.096991                  27.725501\n",
       "16967      23.096991                  27.725501\n",
       "\n",
       "[16968 rows x 2 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outtrn_cumsum</th>\n",
       "      <th>HeatingEnergyUsage_cumsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>730.481201</td>\n",
       "      <td>894.805054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>733.558472</td>\n",
       "      <td>917.562744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>747.941467</td>\n",
       "      <td>893.776184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>747.447021</td>\n",
       "      <td>897.516113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>745.776917</td>\n",
       "      <td>916.025879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16963</th>\n",
       "      <td>785.058899</td>\n",
       "      <td>1126.706055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16964</th>\n",
       "      <td>781.190186</td>\n",
       "      <td>1125.688354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16965</th>\n",
       "      <td>778.005005</td>\n",
       "      <td>1123.621582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16966</th>\n",
       "      <td>775.443115</td>\n",
       "      <td>1121.474487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16967</th>\n",
       "      <td>773.465271</td>\n",
       "      <td>1119.930664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16968 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       outtrn_cumsum  HeatingEnergyUsage_cumsum\n",
       "0         730.481201                 894.805054\n",
       "1         733.558472                 917.562744\n",
       "2         747.941467                 893.776184\n",
       "3         747.447021                 897.516113\n",
       "4         745.776917                 916.025879\n",
       "...              ...                        ...\n",
       "16963     785.058899                1126.706055\n",
       "16964     781.190186                1125.688354\n",
       "16965     778.005005                1123.621582\n",
       "16966     775.443115                1121.474487\n",
       "16967     773.465271                1119.930664\n",
       "\n",
       "[16968 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=pd.DataFrame(sc.inverse_transform(y_pred.reshape(-1,2)),columns = ['outtrn_cumsum','HeatingEnergyUsage_cumsum'])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('y.xlsx') as writer:\n",
    "    y_pred.to_excel(writer, sheet_name='y_pred')\n",
    "    y_test.to_excel(writer, sheet_name='y_test')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kty",
   "language": "python",
   "name": "kty"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
